# How can I use AI most effectively early in my career?

I've been experimenting with different AI tools in software engineering over the last few years, and I think it's now quite clear that these tools are here to stay, and software engineers will have to make big changes to their workflows in order to incorporate the benefits of AI into their work.

However, I keep hearing what I believe is a massive misconception – that junior developers will struggle, since a senior developer with an AI subscription will always out-compete them, and that AI will replace a large amount of junior roles. While there is at least some truth in this, I don't believe that's the biggest issue at all and I feel that younger software engineers like myself are slightly missing the point. 

We have the benefit of growing up with these tools, and like every generation that grows up with a technology, there seems to be a natural ability that comes with it. I believe that we may be able to derive a slightly larger benefit on a level playing field. The point people are missing is how do we get ourselves to this level playing field. I see hundreds of people online, who believe that they need to be on top of the next AI trend, in order to 'out-build' senior developers with years more experience – these junior developers are building products which are attempting to rival startups at speeds which I could never dream of competing with. But as they build better and better products, super-charged by AI, I tend to think that they lose out on the main purpose, the reason that everyone started building these side projects in the first place – the learning. People didn't build these side projects to attempt to out-do senior programmers, they did it to learn the skills so they could give themselves a chance to compete in the future. We put ourselves in far more danger of being replaced if we outsource our learning in order to build projects slightly quicker in the short term.

# We all know how to speed up coding - how do we speed up learning?

I've been trying to test out a couple of different ways of development with AI while trying to optimise exclusively for learning.

The first method I tried was creating a highly-detailed prompt for Claude, in the same way you would if you were planning to build a large project, but telling it to never, ever output any code, and instead to tell me what I need to implement at that phase in the project, and offer only direction if needed. 

Whilst this did work initially, it always seemed to forget about it's constraints after a few follow-ups and start outputting code, and while I should also take some of the blame for asking more questions than I probably needed to, it didn't really work as a learning framework for me. I think this was because the line between just asking for direction and blindly generating code is a bit blurred, depending on how much detail it responds with. For example, sometimes if I knew I could find an answer in the language docs, I would just ask Claude the question since I had it open, but whether that would be crossing the line into generating code is unclear.

The next method I'm trialling, is getting it to generate things I might need before the project, and then only referring to these outputs and nothing else. The two parts I'm generating are a Roadmap, which splits the project up into phases, specifically detail what needs to be implemented in order for a phase to be completed. I am also generating comprehensive test cases, which run at then end of each phase, to let me know if I have been successful. Apart from this, no other AI use will be permitted.

I am currently using the framework above, and will report back with my findings!
