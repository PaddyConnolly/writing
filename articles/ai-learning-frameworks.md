## How can I use AI most effectively early in my career?

I've been experimenting with different AI tools in software engineering over the last few years, and I think it's now quite clear that these tools are here to stay, and software engineers will have to make big changes to their workflows in order to incorporate the benefits of AI into their work.

However, I keep hearing what I believe is a massive misconception – that junior developers will struggle, since a senior developer with an AI subscription will always out-compete them, and that AI will replace a large amount of junior roles. While there is at least some truth in this, I don't believe that's the biggest issue at all and I feel that younger software engineers like myself are slightly missing the point. 

We have the benefit of growing up with these tools, and like every generation that grows up with a technology, there seems to be a natural ability that comes with it. I believe that we may be able to derive a slightly larger benefit on a level playing field. The point people are missing is how do we get ourselves to this level playing field. I see hundreds of people online, who believe that they need to be on top of the next AI trend, in order to 'out-build' senior developers with years more experience – these junior developers are building products which are attempting to rival startups at speeds which I could never dream of competing with. But as they build better and better products, super-charged by AI, I tend to think that they lose out on the main purpose, the reason that everyone started building these side projects in the first place – the learning. People didn't build these side projects to attempt to out-do senior programmers, they did it to learn the skills so they could give themselves a chance to compete in the future. We put ourselves in far more danger of being replaced if we outsource our learning in order to build projects slightly quicker in the short term.

## We all know how to speed up coding - how do we speed up learning?

I've been trying to test out a couple of different ways of development with AI while trying to optimise exclusively for learning.

The first method I tried was creating a highly-detailed prompt for Claude, in the same way you would if you were planning to build a large project, but telling it to never, ever output any code, and instead to tell me what I need to implement at that phase in the project, and offer only direction if needed. 

Whilst this did work initially, it always seemed to forget about it's constraints after a few follow-ups and start outputting code, and while I should also take some of the blame for asking more questions than I probably needed to, it didn't really work as a learning framework for me. I think this was because the line between just asking for direction and blindly generating code is a bit blurred, depending on how much detail it responds with. For example, sometimes if I knew I could find an answer in the language docs, I would just ask Claude the question since I had it open, but whether that would cross the line into generating code is unclear.

The next method I trialled was getting it to generate things I might need before the project, and then only referring to those outputs and nothing else. The three parts I generated are a Roadmap, which splits the project up into phases, specifically detailing what needs to be implemented in order for a phase to be completed. I am also generating comprehensive test cases, which run at the end of each phase, to let me know if I have been successful. The final part is a list of required write-ups - at each stage, it will give me questions to answer in order to make me prove my understanding. Apart from this, no other AI use will be permitted.

## Results

I recently completed [padis](https://github.com/PaddyConnolly/padis.git), my Redis clone in Rust using the framework above. Overall, I think it was successful, I really feel like I learned a lot, at will definitely be using (a version of) this framework going forward. I was really pleased with how quickly it let me move when I had stalled a bit, so that I could get back to the learning part ASAP. For example, when implementing an unfamiliar project such as this, typically I would have to spend ages writing tests (or worse - spamming print statements) to work out if I had got my code working. This framework let me instantly see if I had understood the problem and implemented a successful solution, which meant I could jump straight into the next problem.

However, there are still a couple of things about the framework that I would change. The first is that it doesn't seem possible to fully pre-plan a project with AI. For example, it gave me a type for a specific variable which confused me, and I did some research and found that it was suboptimal, so I changed it. However, this meant that I had to go through almost every test and update the function signatures – but this didn't take very long, and I found the benefits of having testing 'checkpoints' were far more important.

The Roadmap-based project structure really worked, once my tests passed, I felt like I had really learned a chunk of system design or language syntax that I hadn't before. The only small problem I had with it is that the 'No AI use permitted' rule I had set for myself started to backfire a bit. Since I wasn't able to ask it questions about it's design choices, I felt that I was losing some learning opportunities, so I carved out an exception for myself in those cases.

Finally, the write-ups – At the start of the project, right after completing the first phase, I wrote about 5 write-ups, which felt very helpful, it helped me identify holes in my knowledge or errors, lifetimes and other language features. However, in the following phases, I didn't feel the write-ups that were suggested would be very helpful at all, so I guess the main takeaway from this would be to front-load the write-ups a bit more next time, since that's sort of the main research phase of the project. I did also find that it was useful to ask for clarification from the AI when I was unsure making a statement in my write-ups. Since I never used it to generate actual write-up content, only to answer my questions, I felt that creating another exception to the 'No AI' rule was justified.
